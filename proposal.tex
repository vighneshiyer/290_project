\documentclass[11pt]{article}

\usepackage{float}
\usepackage{hyperref}
\usepackage{graphicx}
% formatting
\usepackage{verbatim}
\usepackage{moreverb}
\usepackage{minted}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage[listings]{tcolorbox}
\usepackage{enumerate}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\addbibresource{references.bib}
\usetikzlibrary{arrows,automata, positioning}
\let\verbatiminput=\verbatimtabinput
\def\verbatimtabsize{4\relax}

\tcbset{
texexp/.style={colframe=black, colback=lightgray!15,
         coltitle=white,
         fonttitle=\small\sffamily\bfseries, fontupper=\small, fontlower=\small},
     example/.style 2 args={texexp,
title={Question \thetcbcounter: #1},label={#2}},
}

\newtcolorbox{texexp}[1]{texexp}
\newtcolorbox[auto counter]{texexptitled}[3][]{%
example={#2}{#3},#1}

\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textwidth}{6.5in}

% Useful macros

\newcommand{\note}[1]{{\bf [ NOTE: #1 ]}}
\newcommand{\fixme}[1]{{\bf [ FIXME: #1 ]}}
\newcommand{\wunits}[2]{\mbox{#1\,#2}}
\newcommand{\um}{\mbox{$\mu$m}}
\newcommand{\xum}[1]{\wunits{#1}{\um}}
\newcommand{\by}[2]{\mbox{#1$\times$#2}}
\newcommand{\byby}[3]{\mbox{#1$\times$#2$\times$#3}}


\newenvironment{tightlist}
{\begin{itemize}
 \setlength{\parsep}{0pt}
 \setlength{\itemsep}{-2pt}}
{\end{itemize}}

\newenvironment{titledtightlist}[1]
{\noindent
 ~~\textbf{#1}
 \begin{itemize}
 \setlength{\parsep}{0pt}
 \setlength{\itemsep}{-2pt}}
{\end{itemize}}

% Change spacing before and after section headers

\makeatletter
\renewcommand{\section}
{\@startsection {section}{1}{0pt}
 {-2ex}
 {1ex}
 {\bfseries\Large}}
\makeatother

\makeatletter
\renewcommand{\subsection}
{\@startsection {subsection}{1}{0pt}
 {-1ex}
 {0.5ex}
 {\bfseries\normalsize}}
\makeatother

% Reduce likelihood of a single line at the top/bottom of page
\clubpenalty=2000
\widowpenalty=2000

% Other commands and parameters
\pagestyle{myheadings}
\setlength{\parindent}{0in}
\setlength{\parskip}{10pt}

% Commands for register format figures.
\newcommand{\instbit}[1]{\mbox{\scriptsize #1}}
\newcommand{\instbitrange}[2]{\instbit{#1} \hfill \instbit{#2}}

% Break lines on texttt text on underscores
% See: https://tex.stackexchange.com/questions/315369/how-to-deal-with-bad-line-wrapping-of-texttt
\newcommand*\ttvar[1]{\texttt{\expandafter\dottvar\detokenize{#1}\relax}}
\newcommand*\dottvar[1]{\ifx\relax#1\else
  \expandafter\ifx\string_#1\string_\allowbreak\else#1\fi
  \expandafter\dottvar\fi}

\graphicspath{{./figs/}}
\newcommand{\itwos}{I\textsuperscript{2}S}

\begin{document}

\def\PYZsq{\textquotesingle}
\title{\vspace{-0.4in}\Large \bf EE290C Project Proposal: Performance and Energy Characterization of Gemmini, BOOM, and NVDLA Using State-Sampling from Firesim FPGA Simulation\vspace{-0.1in}}
\author{Vighnesh Iyer, Billy Chau}
\date{}
\maketitle

\newcommand{\headertext}{EE290C Project Proposal}
\markboth{\headertext}{\headertext}
\thispagestyle{empty}

\section{Background and Motivation}
The architecture and VLSI literature has produced a litany of dedicated ML accelerators over the last 3 years.
Most of these accelerators exploited unique dataflows, weight/activation sparsity, integer arithmetic, novel circuit techniques, or many other techniques to achieve a claimed perf/watt advantage over prior work.

However, architecture papers typically measure the energy consumption of the proposed accelerator against a baseline using a (Python/C++) model of their accelerator, and the energy numbers may suffer from poor accuracy.
Some papers use HLS to generate RTL implementations of different architectures but the energy calculation from a synthesized netlist and RTL simulation is limited by the speed of simulation, and thus only small networks can be evaluated at the RTL-power-estimation-level.

On the other hand, chip/VLSI papers measure the energy consumption of their accelerator empirically using the taped out chip, but do not have a reference accelerator implementation taped-out to compare against.
Furthermore, once a chip is taped out, the power consumption cannot be measured for individual parts of the accelerator (at module-granularity) and cycle-by-cycle energy numbers cannot be extracted.

\section{Prior Work}

Strober\autocite{strober} is a framework which can generate fast and cycle-accurate sample-based energy simulator using Chisel for any arbitrary RTL running on FPGA. It has achieved less than
5 percents error with 99.9 percents confidence against commercial CAD tools with more
than two orders of magnitude speedup over existing microarchitectural simulators and
four orders of magnitude speedup over commercial Verilog simulators.

\textbf{Highlights}

State Snapshotting using Scan Chain - As detailed information of simulation is required
for an accurate power model, a basic scan chain is embedded into the design to capture
a replayable RTL snapshot with both register and SRAM values. Using the hardware
construction language Chisel, all custom transforms and FAME1 transform can be easily
mapped and wrapped around the RTL design.

Sample-based Energy Simulation - Based on the central limit theorem of statistics,
a representative estimator of the power model can be generated given random sampling
and enough snapshot samples. However, knowing the length of the program's execution
is impossible, so the reservoir sampling technique is used to address this problem.

Fine-grained level Simulation and Checking - Independent replayable snapshots are replayed in parallel in
commercial gate-level simulators such as VCS for accurate power analysis. To ensure the correctness of the execution, the output values
of the design are compared with the output traces.

Simmani\autocite{simmani} is an FPGA-accelerated framework which automatically selects signals most correlated with power dissipation and trains power models in terms of the selected signals for any RTL design. It has achieved accurate power models with acceptable errors on real world machine learning application such as SqueezeNet running with Rocket Core and Hwacha Vector Accelerator.

\textbf{Highlights}

Activity Counter Insertion and FPGA accelerated simulation - Utilizing the Strober framework, any RTL designs are automatically transformed for FPGA-accelerated RTL simulation. The framework is also used to obtain runtime power traces from FPGAs by inserting activity counters.

Toggle Density Matrix with Principal Components Projection - In order to train an accurate power model, toggle pattern matrix is used to represent signals and their toggle frequencies. The intuition behind is that signals showing similar toggle patterns have similar effect on dynamic power dissipation and can be factored to share the same coefficient in the power model, thus minimizing modeling error. However, it suffers from the curse of dimensionality like other machine learning algorithms; therefore, SVD-based dimensionality reduction algorithm is used to extract the top k dimensions.

Automatic Signal Selection - Given N, the number of signals selected from Bayesian Information Criterion, k-means++ algorithm is run to cluster the signals into groups i.e. signals with similar toggle pattern are grouped together. Then, the signals that are the closest to the center of each cluster are selected, which will be the regression variables in power model training.

Power Model Regression - Using Elastic Net for variable regularization and selection with k-fold cross-validated hyperparameters, a regression model is trained using the toggle density matrix and the groud truth power traces obtained from commercial CAD tools calculated from RTL VCD dumps.

DESSERT\autocite{dessert} is an FPGA-accelerated framework for effective simulation-based RTL verification and debugging. It has achieved almost no performance overhead with hardware-based assertion checking and insignificant performance overhead for software-based exhaustive checking in comparison to commercial CAD tools.

\textbf{Highlights}

Error Capturing using Scan Chain - Following the technique in the Strober framework, scan chain based snapshotting is used for error capturing in DESSERT. There are two constructs supporting assertion and logs in FIRRTL: stop and printf, and they are mapped automatically from the source code by DESSERT. In order to detect and replay errors efficiently, two identical and deterministic simulators are run in parallel. The leading master instance is to detect the target RTL bugs while the lagging instance is to checkpoint the target RTL state.

Software-based Golden Model Checking - When the logs are generated from FPGA, they are sent to the
buffers in the software simulation driver through DMA. They are then compared with a software-based golden model such as Spike for exhaustive error checking.

\section{Proposal}
We propose a framework that enables:
\begin{itemize}
  \item RTL-fidelity simulation of ML accelerators over full DNN inference passes

    We plan to re-use the Firesim infrastructure that automatically transforms arbitrary RTL to a deterministic, cycle-accurate model that executes on an FPGA.

  \item Gate-level fidelity energy modeling (with module-level granularity)

    We plan to modify and add passes to Golden Gate that add a stitched scan chain and SRAM hijack ports that allows the host to inject and pull all $\mu$Arch state to and from the DUT.
    This technique is distinct from DESSERT and STROBER since those works use a shadow scan chain that cannot inject state into the DUT, and may be more resource intensive.

    This allows us to advance simulation time, pause at random intervals, and dump the DUT state to the host, similar to STROBER.
    The randomly sampled RTL-level activity traces are formally mapped into gate-level traces and fed into Voltus with a gate-level synthesized netlist for cycle-by-cycle energy numbers.

  \item Performance instrumentation and bottleneck analysis (PE utilization, memory traffic analysis)

    We plan to use the auto-instrumentation (AutoCounter) feature in FirePerf\autocite{fireperf} to capture design-specific performance counters to evaluate bottlenecks in DNN inference.
    We also plan to instrument the off-chip memory interface to record the DRAM address and transfer size access patterns.

  \item Energy estimation of DRAM accesses

    The memory access trace can be replayed in DRAMSim2\autocite{dramsim2} to extract average power numbers across time.
    DRAM access energy is often neglected in RTL-level power analyses and isn't done in the STROBER flow.

  \item Exploration of the impact different dataflows and tiling patterns on energy and performance

    Finally, once the framework described has been implemented, it can be used to guide software optimizations.
\end{itemize}

We plan to use this framework to evaluate Gemmini\autocite{gemmini} and BOOM, and if time permits, NVDLA on Firesim\autocite{nvdlafiresim}.

\section{Project Infrastructure}
For the initial phase of the project, we don't require any special infrastructure apart from our laptops and the BWRC servers for Genus/Jasper/Voltus (we hope VPN works).
Once software simulation is successful, we will use some AWS F1 instances.

\section{Project Timeline}

\begin{enumerate}
  \item \textbf{Checkpoint 1 (4/10)}: RTL simulation of a simple circuit (Risc/GCD) after default Firesim transformation, ASAP7 Genus synthesis of the circuit and SRAM macros, formal mapping of RTL VCD to gate-level VCD, scan-chain stitching and SRAM hijack FIRRTL pass working in RTL simulation
  \item \textbf{Checkpoint 2 (4/24)}: Sample circuit simulating on F1 FPGA, $\mu$Arch state dumping, initial energy estimation evaluation
  \item \textbf{Final Report (5/8)}: Rocket with Gemmini simulating on F1 FPGA, DRAM interface and Gemmini-specific performance instrumentation, Gemmini energy estimation for pre-written ResNet50 and Mobilenet implementations, DRAMSim2 energy estimation
\end{enumerate}

The timeline is quite aggressive and there may be points where we find ourselves stuck.
It is likely that the custom FIRRTL passes introduce difficult to find bugs and may delay this timeline.
It is not clear how to perform formal mapping of RTL VCDs to gate VCDs, but there's probably a Cadence RAK for it.

\printbibliography

\end{document}
